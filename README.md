# DeepSeekLocal - VS Code Extension

**DeepSeekLocal** is a VS Code extension that integrates **DeepSeek-R1 (8B)** **locally** using [Ollama](https://github.com/jmorganca/ollama). It provides a simple webview interface to chat with DeepSeek and get AI-powered responses.

---

## 🚀 Features

- 🔹 **Interactive Chat Interface** - Ask questions and get responses from DeepSeek.
- 🔹 **Streaming Responses** - Get real-time AI-generated responses.
- 🔹 **Seamless Integration** - Works directly inside VS Code.
- 🔹 **Lightweight & Fast** - Uses local AI inference via Ollama.

---

## 📦 Installation

### 1️⃣ Prerequisites

- Install **Node.js** (if not installed) - [Download Here](https://nodejs.org/)
- Install **Ollama** and **DeepSeek Model**:
  ```sh
  curl -fsSL https://ollama.ai/install.sh | sh
  ollama pull deepseek-r1:8b
  ```

  ## TO RUN:

  I have uploaded the .vsix in the repository. Directly open it using VSCode Extensions.

_Note: I did come with the idea of this extension. I followed a tutorial on YouTube by Chaao Charles (https://www.youtube.com/watch?v=cqFRE9c8048) and uploaded it on GitHub for ease of access._
